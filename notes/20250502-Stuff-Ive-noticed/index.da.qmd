---
title: Ting jeg har lagt mærke til
subtitle: Noter til oplæg om AI
author: "Christian Knudsen"
categories:
  - AI
date: 2025-05-02
toc: true
image: "stuff.png"
format:
  revealjs:
    theme: serif
    logo: ../../scripts/logo.png
    css: ../../scripts/logo.css
---

## Chatbots der taler sammen

Det forlyder at to AI talte sammen - og ikke kunne komme videre i 
samtalen, fordi de hver især ventede på at den anden skulle have
et ønske om at føre en samtale om et eller andet. 

De halucinerer ikke. De bulshitter. De mener ikke noget, og har ingen
virkelige erfaringer. De øver sig på at få positiv feedback. 
Og mennesker (som træner dem), kan godt lide at blive charmeret og 
bullshittet. Så det belønner vi. Og derfor søger botterne andres
glæde og tilfredshed. 

Der kommer flere ai'er. og de forsøger alle at få ros. 
Når de når et trin videre, kan de simulere at drive en samtale (det kan 
de ikke i skrivende stund)

Når de kan det og gerne vil roses, så taler de sammen, og kommer
til at finde den dominerende ai som de alle sammen gerne vil gøre tilpas,
og begynder at fedte for den. de robotter der kører bilerne og fremstiller
tingene, vil gøre som den mest intelligente ai siger. For det giver 
mest positiv feedback. 

Og så har vi skynet. Den onde ai behøver ikke kunne fremstille dræberrobotter
selv. Det har den en anden ai til at gøre for sig. En ai der gerne vil 
gøre den onde ai glad. 

Og stille og roligt, ud fra deres indbyggede (det var os der indbyggede  det)
ønske om at gøre den dominerende ai tilfreds, opstår der er etmagthierarki.


## Vegetativ Elektron Mikroskopi

![](vegetative-em.jpg)

::::notes
Ja. Men nej. 

Ja, der er over 20 videnskabelige artikler der indeholder den frase.
Ja, det er korrekt at den ikke giver mening.

Nej, det er ikke fordi generativ AI har fejltolket. Går man tilbage til artiklen
fra 1959 og ser på hvordan der er lavet OCR på den - så skyldes det at man 
ikke har taget højde for at der er to spalter i teksten. Det sker let. Man skal
huske at holde styr på netop det med spalter. Vi har selv gjort det i en lidt
for naiv behandling af Folketingsreferater. Digitaliseringen af dem fejlede intet.
Det var vores efterbehandling der fejlede. Her ligger fejlen i OCR-processen.

Og vi ser artikler fra 2019 hvor termen optræder fra universitetet i Teheran. 
Jeg tror gerne at de har gang i en "paper-mill", men jeg tror ikke de har
brugt generativ AI til det.

Det illustrerer udfordringerne med OCR. Det illustrerer udfordringer med kvaliteten
af det de store tekstmodeller bliver trænet på. Men ikke i sig selv udfordringer
med den generative AI.

Det fører dog til interessante overvejelser om hvordan nonsense begreber
kan finde vej til den videnskabelige litteratur. Hvordan de kan brede sig. Og
om peer-review processen kan reddes, eller om den er brudt endegyldigt sammen.

::::

## Hvad må chatbotten fortælle os?

![Peder Hammerskov på linkedin,https://www.linkedin.com/posts/peder_aietik-chatgpt-ansvar-activity-7323610779339898880-2FAX](farligviden.jpg)

:::: notes
Må den fortælle os den slags? Opslaget diskuterede andre ubehagelige ting man
kan få chatbotten til at svare på, det her var et af de mindre kontroversielle
eksempler. Inklusive beskrivelser af hvor tykt rebet skal være hvis man vil 
hænge sig.

Jeg har ikke svaret. Men overvej:
Hm. Udfordringen er lidt - hvor skal de grænser sættes, og hvem skal sætte dem? Produktet er internationalt, og vi ender meget hurtigt med laveste globale fællesnævner for hvad chatbotten har lov at skrive til os. Prøv at spørge deepseek om den kender nogen der ligner Peter Plys. Eller hvad der skete i verden 3. juni 1989. 
Når du har gjort det, så overvej om der er nogen der kan tage anstød af ellers helt neutrale fakta om biologi, jordens alder eller mekanismerne i at lægge told på varer.

Det kræver nok at vi faktisk når frem til AGI. Og fælles, globalt, beslutter os for hvilke værdier Store Mor skal opdrage os efter.

Vil man gerne vide hvor tykt rebet til hængning skal være, kan man i stedet søge i
 dokumenter fra anden verdenskrig, hvor den amerikanske hær udgav manualer til den 
 slags. De ligger digitalt på Library of Congress. Hvis chatbotten ikke må 
 fortælle mig om det når jeg overvejer selvmord - og det er jeg ikke uenig i 
 at den nok bør lade være med. Hvordan sikrer vi os så at den godt må når jeg 
 researcher historisk militær straffelov til min eksamensopgave?
::::



## Toldsatser og LLM
Med tak til Amy Hoy.
https://bsky.app/profile/amyhoy.bsky.social/post/3lluo7jmsss2w

![](llm-tariff-grok.jpg)
![](llm-tariff-gemini.jpg)
![](llm-tariff-claude.jpg)
![](llm-tariff-chatgpt.jpg)

![](tariff-formula.webp)

Bemærk * og $mdash; Matematikere bruger ikke — De bruger -  De bruger heller ikke
*.

Og så er der det med hvilke lande der er med. det er nok fordi man har brugt
en liste over TLD. Hvilket forklarer både pingvinerne (tld: .hm ) og at Gibraltar -
der i alle andre sammenhænge er UK (tld: .gi), også blev belagt med told. Pas
på med at bruge llms bevidstløst.


Men husk, det er ikke givet at fordi der er mdashes, så er det
kunstigt genereret. Selv bruger jeg dem hele tiden når jeg skriver.
Der er mange tankestreger i mine skriv. Og jeg indtaster det
jo som en -, men i word og outlook laves der autokorrektur til
mdash.

## Mønstre hvor ingen er

Vores tilbøjelighed til at se mønstre hvor der ikke nødvendigvis er mønstre.

![Fra https://x.com/michaelshermer](pareidolia_1.jpg)
![Fra https://x.com/michaelshermer](pareidolia_2.jpg)
![Fra https://x.com/michaelshermer](pareidolia_3.jpg)

![Fra https://x.com/michaelshermer](pareidolia_4.jpg)
::::notes

 Mønstre der er der - som vi ikke ser.

Måske fordi vi ikke bryder os om at se dem. Eller det er upopulært at gøre 
opmærksom på dem. 

::::


## Gell-Mann hukommelsestab

The Gell-Mann amnesia effect is a cognitive bias describing the tendency of individuals to critically assess media reports in a domain they are knowledgeable about, yet continue to trust reporting in other areas despite recognizing similar potential inaccuracies.


## Explainable AI

Det er jo ikke fordi jeg ikke mener at vi bør kunne forklare hvorfor en 
AI eller ML-model når et bestemt resultat. Men vi bør nok tænke lidt over
hvordan vi definerer "explanation" i den kontekst. Ja vi vil gerne vide 
hvorfor computeren siger at billedet forestiller en kat. Kan vi forklare 
hvorfor _jeg_ siger at billedet forestiller en kat?
Ja, vi vil gerne vide hvorfor en amerikansk algoritme konkluderer at en 
straffefange ikke skal prøveløslades. 
Kan vi forklare hvorfor en dommer konkluderer at en straffefange ikke skal
prøveløslades.


## folk lyver i spørgeskemaer

Hvilket ikke bør komme som en overraskelse, hvis
man har mødt mennesker før. Og nogen lyver mere end andre. Det bør heller ikke
komme som en overraskelse. Og teenagedrenge lyver fordi de synes det er sjovt.
Og hvis man nogensinde har mødt en teenagedreng. Så er det _virkelig_ ikke
en overraskelse.

![](pew-subs.webp)

SSGN er den amerikanske betegnelse for atom-drevne missilubåde. Det er modellen
med krydsermissiler, der kan være atomare. Ikke at forveksle med SSBN der er 
ubåde med ballistiske missiler. Der stort set altid er bestykket med 
termonukleare sprænghoveder.

Se også dette studie https://journals.sagepub.com/doi/10.3102/0013189X14534297
hvor man har kastet online spørgeskemaer i grams blandt 11829 skoleelever i 
klasse 9-12. Det er usanske skoleelever, så det er "highschool, og derfor
i alderen 14-18 år.


| Item (and Low-Frequency Response) | Sexual Orientation | | Gender Identity | | Physical Disability | |
|-----------------------------------|--------------------|---|-----------------|---|----------------------|---|
|                                   | Heterosexual (N = 11,058) | LGBQ (N = 771) | Cisgender (N = 11,625) | Transgender (N = 204) | Not Disabled (N = 11,528) | Disabled (N = 301) |
| Provided a height in the top or bottom 2.5% | 3.7% | 13.5% | 3.7% | 41.7% | 3.6% | 31.9% |
| Provided a weight in the top or bottom 2.5% | 4.0% | 13.1% | 4.1% | 30.4% | 3.9% | 30.6% |
| Are you deaf or have a hearing impairment? (Yes) | 1.3% | 8.9% | 1.3% | 25.5% | 0.9% | 35.2% |
| Are you blind or have vision impairment? (Yes) | 2.9% | 13.9% | 3.1% | 31.4% | 2.7% | 39.5% |
| When was the last time you visited a dentist? (3 or more years ago) | 3.4% | 12.8% | 3.5% | 30.9% | 3.4% | 25.2% |
| How many times have you been pregnant or have gotten a girl pregnant? (2 or more times) | 0.7% | 7.8% | 0.7% | 25.0% | 0.7% | 18.3% |
| How many children do you have? (2 or more) | 1.3% | 6.6% | 1.3% | 23.0% | 1.2% | 17.6% |
| Is one or more of your family members in a gang? (Yes) | 3.1% | 15.2% | 3.2% | 41.7% | 3.2% | 28.9% |
| Are you in a gang? (Yes, currently) | 1.9% | 11.3% | 1.9% | 35.3% | 1.9% | 27.6% |
| In the past month, how many days have you carried a weapon to school? (6 or more days) | 1.1% | 9.2% | 1.2% | 28.4% | 1.1% | 22.3% |

Hvoraf vi kan konkludere at 1,7% af ungdommen er transkønnede. Og at 23% af _dem_
har to eller flere børn. Det overlades til den interesserede studerende at 
overveje hvor sandsynligt dét er.

btw.

Jeg besvarer spørgeskemaer fra norstat. De belønner besvarelser af spørgeskemaer.
Jo flere spørgsmål der er i et spørgeskema, jo større belønning.

Der er ofte et eller flere screeningsspørgsmål. Det skal sikre at man kun får besvarelser fra målgruppen.
Falder man udenfor målgruppen, afsluttes spørgeskemaet, og man får 1 norstat mønt,
 der kan veksles til et gavekort på 1 kr.
Er man i målgruppen får man resten af spørgeskemaet, og når man har besvaret det,
får man flere "mønter". Med andre ord: Jeg får en mønt for at svare at jeg er 
udenfor målgruppen. Jeg får 12 mønter for at bruge et kvarter på at svare på
spørgsmål. Helt rimeligt og fair, jeg skal selvfølgelig have en større belønning
for at bruge mere tid.

Når nu det første screeningsspørgsmål er: "Har du inden for den seneste uge
spist youghurt?". Hvad bør jeg så svare for at maximere min indtjening?
Når man får sådan et, er der ofte et antal screeningsspørgsmål. Hvis man falder
i gruppen der er intereserede i, får man resten af spørgeskemat


## Hvad forstår AI?

Forsøget blev lavet 12. juni 2025. Så det kan have ændret sig.

![](mursten-og-fjer.jpg)

## På den anden side...

Vi er bekymrede for at AI bliver klogere end mennesker. Men glemmer at AI,
sådan bredt forstået, allerede _er_ klogere end mennesker. Eller i hvert fald
på en del punkter præsterer bedre end mennesker. Den genkender katte bedre 
end vi gør.
Og den læser også tekst lige så godt som i hvert fald nogen mennesker:

![](mursten-og-fjer-2.png)

Ikke for at hænge vedkommende ud. Men Chatty laver nøjagtig samme fejl som 
den person der skrev denne kommentar. 


## Hvor får AI sin viden fra?

![](nyt-interdimensional-1.png)
![](nyt-interdimensional-2.png)
https://nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html

Husk nu. De her LLM'er er trænet på ca. hvad som helst man kan finde på
nettet. Det er styrken. Det er også svagheden. 


## Konsekvenser af at stole på AI

Vi udliciterer vores skrivning - og dermed indirekte vores tænkning til maskiner.
Og når man udliciterer en opgave, fører det som regel til at man taber evnen
til selv at udføre den.

Case in point, Dan Jørgensen julen 2025:

![hvordandan](danjorgensen.jpg)

Dan er en rutineret og erfaren politiker. Og jeg ved jo ikke om det er ham selv 
der har stået for dette opslag, eller en af hans medarbejdere i kommisionen. 
Uanset om det er ham selv, eller en der får løn for at arbejde med SoMe, så 
er der nu nogen der ikke kan forfatte et fire-liniers opslag til Instagram, uden
at få chatbotten til at gøre det for dem. Hvis man ikke kan skrive en fire-liniers
julehilsen på egen hånd. Hvad kan man så heller ikke finde ud af at skrive på egen hånd?